#!/usr/bin/env python3
"""
CampusWorld æ•°æ®åº“æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•æ–°çš„ä¼˜åŒ–æ•°æ®åº“ç»“æ„çš„æ€§èƒ½
åŒ…æ‹¬æŸ¥è¯¢æ€§èƒ½ã€ç´¢å¼•æ•ˆæœã€å¹¶å‘æ€§èƒ½ç­‰

ä½œè€…ï¼šAI Assistant
åˆ›å»ºæ—¶é—´ï¼š2025-08-24
"""

import os
import sys
import time
import random
import uuid
from datetime import datetime, timedelta
from typing import List, Dict, Any
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sqlalchemy import create_engine, text, func
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import SQLAlchemyError

# é…ç½®
DATABASE_URL = os.getenv('DATABASE_URL', "postgresql://campusworld:campusworld@localhost:5433/campusworld")


class DatabasePerformanceTester:
    """æ•°æ®åº“æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, database_url: str):
        self.engine = create_engine(database_url)
        self.Session = sessionmaker(bind=self.engine)
        
    def generate_test_data(self, node_count: int = 1000, relationship_count: int = 5000):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        print(f"ğŸ”„ ç”Ÿæˆæµ‹è¯•æ•°æ®: {node_count} ä¸ªèŠ‚ç‚¹, {relationship_count} ä¸ªå…³ç³»...")
        
        try:
            with self.Session() as session:
                # ç”ŸæˆèŠ‚ç‚¹æ•°æ®
                nodes = []
                for i in range(node_count):
                    node_type = random.choice(['user', 'campus', 'world', 'world_object'])
                    node = {
                        'uuid': str(uuid.uuid4()),
                        'type_code': node_type,
                        'name': f'æµ‹è¯•{node_type}{i}',
                        'description': f'è¿™æ˜¯ç¬¬{i}ä¸ª{node_type}çš„æè¿°',
                        'is_active': random.choice([True, True, True, False]),  # 75% æ´»è·ƒ
                        'is_public': random.choice([True, True, False]),  # 67% å…¬å¼€
                        'access_level': random.choice(['normal', 'vip', 'admin']),
                        'attributes': {
                            'score': random.randint(1, 100),
                            'level': random.randint(1, 50),
                            'status': random.choice(['active', 'inactive', 'pending']),
                            'created_by': f'user_{random.randint(1, 100)}',
                            'tags': random.sample(['tag1', 'tag2', 'tag3', 'tag4', 'tag5'], random.randint(1, 3))
                        },
                        'tags': random.sample(['çƒ­é—¨', 'æ¨è', 'æ–°ç”¨æˆ·', 'æ´»è·ƒ', 'VIP'], random.randint(1, 3))
                    }
                    nodes.append(node)
                
                # æ‰¹é‡æ’å…¥èŠ‚ç‚¹
                for node_data in nodes:
                    session.execute(text("""
                        INSERT INTO nodes (
                            uuid, type_id, type_code, name, description, is_active, 
                            is_public, access_level, attributes, tags
                        )
                        SELECT 
                            :uuid::uuid,
                            nt.id,
                            :type_code,
                            :name,
                            :description,
                            :is_active,
                            :is_public,
                            :access_level,
                            :attributes::jsonb,
                            :tags::jsonb
                        FROM node_types nt
                        WHERE nt.type_code = :type_code
                    """), node_data)
                
                session.commit()
                print(f"  âœ… ç”Ÿæˆäº† {node_count} ä¸ªèŠ‚ç‚¹")
                
                # ç”Ÿæˆå…³ç³»æ•°æ®
                relationships = []
                for i in range(relationship_count):
                    source_id = random.randint(1, node_count)
                    target_id = random.randint(1, node_count)
                    if source_id != target_id:
                        rel_type = random.choice(['member', 'friend', 'owns', 'location'])
                        relationship = {
                            'uuid': str(uuid.uuid4()),
                            'type_code': rel_type,
                            'source_id': source_id,
                            'target_id': target_id,
                            'is_active': random.choice([True, True, True, False]),
                            'weight': random.randint(1, 10),
                            'attributes': {
                                'created_at': datetime.now().isoformat(),
                                'reason': f'å…³ç³»åŸå› {i}',
                                'strength': random.randint(1, 100)
                            }
                        }
                        relationships.append(relationship)
                
                # æ‰¹é‡æ’å…¥å…³ç³»
                for rel_data in relationships:
                    session.execute(text("""
                        INSERT INTO relationships (
                            uuid, type_id, type_code, source_id, target_id, 
                            is_active, weight, attributes
                        )
                        SELECT 
                            :uuid::uuid,
                            rt.id,
                            :type_code,
                            :source_id,
                            :target_id,
                            :is_active,
                            :weight,
                            :attributes::jsonb
                        FROM relationship_types rt
                        WHERE rt.type_code = :type_code
                    """), rel_data)
                
                session.commit()
                print(f"  âœ… ç”Ÿæˆäº† {len(relationships)} ä¸ªå…³ç³»")
                
                return True
                
        except SQLAlchemyError as e:
            print(f"  âŒ ç”Ÿæˆæµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return False
            
    def test_basic_queries(self):
        """æµ‹è¯•åŸºç¡€æŸ¥è¯¢æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•åŸºç¡€æŸ¥è¯¢æ€§èƒ½...")
        
        results = {}
        
        try:
            with self.Session() as session:
                # æµ‹è¯•1: ç®€å•æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("SELECT COUNT(*) FROM nodes WHERE is_active = TRUE"))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['simple_count'] = query_time
                print(f"  âœ… ç®€å•è®¡æ•°æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•2: ç±»å‹æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("SELECT COUNT(*) FROM nodes WHERE type_code = 'user'"))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['type_query'] = query_time
                print(f"  âœ… ç±»å‹æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•3: å±æ€§æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("SELECT COUNT(*) FROM nodes WHERE attributes @> '{\"status\": \"active\"}'::jsonb"))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['attribute_query'] = query_time
                print(f"  âœ… å±æ€§æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•4: æ ‡ç­¾æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("SELECT COUNT(*) FROM nodes WHERE tags ? 'çƒ­é—¨'"))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['tag_query'] = query_time
                print(f"  âœ… æ ‡ç­¾æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•5: å¤åˆæŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM nodes 
                    WHERE type_code = 'user' 
                    AND is_active = TRUE 
                    AND attributes @> '{"level": 10}'::jsonb
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['complex_query'] = query_time
                print(f"  âœ… å¤åˆæŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
        except SQLAlchemyError as e:
            print(f"  âŒ åŸºç¡€æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return {}
            
        return results
        
    def test_graph_queries(self):
        """æµ‹è¯•å›¾æŸ¥è¯¢æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•å›¾æŸ¥è¯¢æ€§èƒ½...")
        
        results = {}
        
        try:
            with self.Session() as session:
                # æµ‹è¯•1: å…³ç³»æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM relationships r
                    JOIN nodes n1 ON r.source_id = n1.id
                    JOIN nodes n2 ON r.target_id = n2.id
                    WHERE r.type_code = 'member' AND r.is_active = TRUE
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['relationship_query'] = query_time
                print(f"  âœ… å…³ç³»æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•2: è·¯å¾„æŸ¥è¯¢ï¼ˆ2è·³ï¼‰
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM (
                        SELECT DISTINCT r1.source_id, r2.target_id
                        FROM relationships r1
                        JOIN relationships r2 ON r1.target_id = r2.source_id
                        WHERE r1.type_code = 'member' AND r2.type_code = 'owns'
                        AND r1.is_active = TRUE AND r2.is_active = TRUE
                    ) paths
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['path_query_2hop'] = query_time
                print(f"  âœ… 2è·³è·¯å¾„æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•3: èšåˆæŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("""
                    SELECT 
                        n.type_code,
                        COUNT(*) as node_count,
                        AVG((n.attributes->>'score')::int) as avg_score
                    FROM nodes n
                    WHERE n.is_active = TRUE
                    GROUP BY n.type_code
                    ORDER BY node_count DESC
                """))
                rows = result.fetchall()
                query_time = time.time() - start_time
                results['aggregation_query'] = query_time
                print(f"  âœ… èšåˆæŸ¥è¯¢: {query_time:.4f}s ({len(rows)} ä¸ªåˆ†ç»„)")
                
        except SQLAlchemyError as e:
            print(f"  âŒ å›¾æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return {}
            
        return results
        
    def test_index_performance(self):
        """æµ‹è¯•ç´¢å¼•æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•ç´¢å¼•æ€§èƒ½...")
        
        results = {}
        
        try:
            with self.Session() as session:
                # æµ‹è¯•1: æ— ç´¢å¼•æŸ¥è¯¢ï¼ˆæ¨¡æ‹Ÿï¼‰
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM nodes 
                    WHERE name ILIKE '%æµ‹è¯•%'
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['no_index_query'] = query_time
                print(f"  âœ… æ— ç´¢å¼•æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•2: æœ‰ç´¢å¼•æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM nodes 
                    WHERE type_code = 'user' AND is_active = TRUE
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['indexed_query'] = query_time
                print(f"  âœ… æœ‰ç´¢å¼•æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
                # æµ‹è¯•3: JSONBç´¢å¼•æŸ¥è¯¢
                start_time = time.time()
                result = session.execute(text("""
                    SELECT COUNT(*) FROM nodes 
                    WHERE attributes @> '{"status": "active", "level": 10}'::jsonb
                """))
                count = result.fetchone()[0]
                query_time = time.time() - start_time
                results['jsonb_index_query'] = query_time
                print(f"  âœ… JSONBç´¢å¼•æŸ¥è¯¢: {query_time:.4f}s ({count} æ¡è®°å½•)")
                
        except SQLAlchemyError as e:
            print(f"  âŒ ç´¢å¼•æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {}
            
        return results
        
    def test_concurrent_performance(self, concurrent_users: int = 10, queries_per_user: int = 100):
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        print(f"ğŸ§ª æµ‹è¯•å¹¶å‘æ€§èƒ½: {concurrent_users} ä¸ªå¹¶å‘ç”¨æˆ·, æ¯ä¸ª {queries_per_user} æ¬¡æŸ¥è¯¢...")
        
        import threading
        import queue
        
        results_queue = queue.Queue()
        
        def worker(worker_id: int):
            """å·¥ä½œçº¿ç¨‹"""
            try:
                engine = create_engine(DATABASE_URL)
                Session = sessionmaker(bind=engine)
                
                query_times = []
                for i in range(queries_per_user):
                    query_type = random.choice(['simple', 'type', 'attribute', 'tag'])
                    
                    with Session() as session:
                        start_time = time.time()
                        
                        if query_type == 'simple':
                            session.execute(text("SELECT COUNT(*) FROM nodes WHERE is_active = TRUE"))
                        elif query_type == 'type':
                            session.execute(text("SELECT COUNT(*) FROM nodes WHERE type_code = 'user'"))
                        elif query_type == 'attribute':
                            session.execute(text("SELECT COUNT(*) FROM nodes WHERE attributes @> '{\"status\": \"active\"}'::jsonb"))
                        elif query_type == 'tag':
                            session.execute(text("SELECT COUNT(*) FROM nodes WHERE tags ? 'çƒ­é—¨'"))
                        
                        query_time = time.time() - start_time
                        query_times.append(query_time)
                        
                results_queue.put({
                    'worker_id': worker_id,
                    'query_times': query_times,
                    'avg_time': statistics.mean(query_times),
                    'total_time': sum(query_times)
                })
                
            except Exception as e:
                results_queue.put({
                    'worker_id': worker_id,
                    'error': str(e)
                })
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        start_time = time.time()
        
        for i in range(concurrent_users):
            thread = threading.Thread(target=worker, args=(i,))
            thread.start()
            threads.append(thread)
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        
        # æ”¶é›†ç»“æœ
        worker_results = []
        while not results_queue.empty():
            worker_results.append(results_queue.get())
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        all_query_times = []
        successful_workers = 0
        
        for result in worker_results:
            if 'error' not in result:
                successful_workers += 1
                all_query_times.extend(result['query_times'])
        
        if all_query_times:
            avg_query_time = statistics.mean(all_query_times)
            total_queries = len(all_query_times)
            qps = total_queries / total_time  # æ¯ç§’æŸ¥è¯¢æ•°
            
            print(f"  âœ… å¹¶å‘æµ‹è¯•å®Œæˆ:")
            print(f"     - æˆåŠŸå·¥ä½œçº¿ç¨‹: {successful_workers}/{concurrent_users}")
            print(f"     - æ€»æŸ¥è¯¢æ•°: {total_queries}")
            print(f"     - æ€»æ—¶é—´: {total_time:.2f}s")
            print(f"     - å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_query_time:.4f}s")
            print(f"     - æŸ¥è¯¢ååé‡: {qps:.2f} QPS")
            
            return {
                'concurrent_users': concurrent_users,
                'successful_workers': successful_workers,
                'total_queries': total_queries,
                'total_time': total_time,
                'avg_query_time': avg_query_time,
                'qps': qps
            }
        else:
            print(f"  âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: æ²¡æœ‰æˆåŠŸçš„æŸ¥è¯¢")
            return {}
            
    def run_performance_test(self):
        """è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹æ•°æ®åº“æ€§èƒ½æµ‹è¯•...")
        print("=" * 60)
        
        # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
        if not self.generate_test_data():
            return False
            
        print()
        
        # 2. åŸºç¡€æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        basic_results = self.test_basic_queries()
        print()
        
        # 3. å›¾æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        graph_results = self.test_graph_queries()
        print()
        
        # 4. ç´¢å¼•æ€§èƒ½æµ‹è¯•
        index_results = self.test_index_performance()
        print()
        
        # 5. å¹¶å‘æ€§èƒ½æµ‹è¯•
        concurrent_results = self.test_concurrent_performance()
        print()
        
        # 6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        self.generate_performance_report(basic_results, graph_results, index_results, concurrent_results)
        
        return True
        
    def generate_performance_report(self, basic_results, graph_results, index_results, concurrent_results):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        # åŸºç¡€æŸ¥è¯¢æ€§èƒ½
        if basic_results:
            print("\nğŸ” åŸºç¡€æŸ¥è¯¢æ€§èƒ½:")
            for query_type, time_taken in basic_results.items():
                print(f"  - {query_type}: {time_taken:.4f}s")
            
            avg_basic_time = statistics.mean(basic_results.values())
            print(f"  - å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_basic_time:.4f}s")
        
        # å›¾æŸ¥è¯¢æ€§èƒ½
        if graph_results:
            print("\nğŸ” å›¾æŸ¥è¯¢æ€§èƒ½:")
            for query_type, time_taken in graph_results.items():
                print(f"  - {query_type}: {time_taken:.4f}s")
            
            avg_graph_time = statistics.mean(graph_results.values())
            print(f"  - å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_graph_time:.4f}s")
        
        # ç´¢å¼•æ€§èƒ½
        if index_results:
            print("\nğŸ” ç´¢å¼•æ€§èƒ½:")
            for query_type, time_taken in index_results.items():
                print(f"  - {query_type}: {time_taken:.4f}s")
            
            # è®¡ç®—ç´¢å¼•æ•ˆæœ
            if 'no_index_query' in index_results and 'indexed_query' in index_results:
                improvement = (index_results['no_index_query'] - index_results['indexed_query']) / index_results['no_index_query'] * 100
                print(f"  - ç´¢å¼•ä¼˜åŒ–æ•ˆæœ: {improvement:.1f}%")
        
        # å¹¶å‘æ€§èƒ½
        if concurrent_results:
            print("\nğŸ” å¹¶å‘æ€§èƒ½:")
            print(f"  - å¹¶å‘ç”¨æˆ·æ•°: {concurrent_results.get('concurrent_users', 0)}")
            print(f"  - æˆåŠŸå·¥ä½œçº¿ç¨‹: {concurrent_results.get('successful_workers', 0)}")
            print(f"  - æ€»æŸ¥è¯¢æ•°: {concurrent_results.get('total_queries', 0)}")
            print(f"  - æ€»æ—¶é—´: {concurrent_results.get('total_time', 0):.2f}s")
            print(f"  - å¹³å‡æŸ¥è¯¢æ—¶é—´: {concurrent_results.get('avg_query_time', 0):.4f}s")
            print(f"  - æŸ¥è¯¢ååé‡: {concurrent_results.get('qps', 0):.2f} QPS")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    print("CampusWorld æ•°æ®åº“æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    database_url = os.getenv('DATABASE_URL', DATABASE_URL)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = DatabasePerformanceTester(database_url)
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    success = tester.run_performance_test()
    
    if success:
        print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ“‹ å»ºè®®:")
        print("1. æ ¹æ®æµ‹è¯•ç»“æœä¼˜åŒ–æ•°æ®åº“é…ç½®")
        print("2. è°ƒæ•´ç´¢å¼•ç­–ç•¥ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½")
        print("3. ç›‘æ§ç”Ÿäº§ç¯å¢ƒçš„å®é™…æ€§èƒ½è¡¨ç°")
    else:
        print("\nâŒ æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")
        sys.exit(1)


if __name__ == "__main__":
    main()
